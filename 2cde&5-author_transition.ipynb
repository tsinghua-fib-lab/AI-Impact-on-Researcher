{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = ['Arial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.','process_data','author_career.pkl'),'rb') as f:\n",
    "    author_career=pickle.load(f)\n",
    "with open(os.path.join('.','process_data','author_selected_dict_fos.pkl'),'rb') as f:\n",
    "    author_selected_dict_fos=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b41889",
   "metadata": {},
   "outputs": [],
   "source": [
    "fos_list=['geology','chemistry','materials science','biology','physics','medicine']\n",
    "fos_name_list=['Geology','Chemistry','Materials','Biology','Physics','Medicine','Total']\n",
    "\n",
    "B_A_time=dict()\n",
    "B_C_time=dict()\n",
    "B_D_C_time=dict()\n",
    "D_C_time=dict()\n",
    "A_O_time=dict()\n",
    "B_O_time=dict()\n",
    "B_D_O_time=dict()\n",
    "C_O_time=dict()\n",
    "D_O_time=dict()\n",
    "for year in range(1800,2022):\n",
    "    B_A_time[year]=list()\n",
    "    B_C_time[year]=list()\n",
    "    B_D_C_time[year]=list()\n",
    "    D_C_time[year]=list()\n",
    "    A_O_time[year]=list()\n",
    "    B_O_time[year]=list()\n",
    "    B_D_O_time[year]=list()\n",
    "    C_O_time[year]=list()\n",
    "    D_O_time[year]=list()\n",
    "\n",
    "num_A_fos=dict()\n",
    "num_B_fos=dict()\n",
    "num_C_fos=dict()\n",
    "num_D_fos=dict()\n",
    "B_A_fos=dict()\n",
    "B_D_fos=dict()\n",
    "B_C_fos=dict()\n",
    "D_C_fos=dict()\n",
    "A_O_fos=dict()\n",
    "B_O_fos=dict()\n",
    "C_O_fos=dict()\n",
    "D_O_fos=dict()\n",
    "B_A_time_fos=dict()\n",
    "B_C_time_fos=dict()\n",
    "B_D_C_time_fos=dict()\n",
    "D_C_time_fos=dict()\n",
    "A_O_time_fos=dict()\n",
    "B_O_time_fos=dict()\n",
    "B_D_O_time_fos=dict()\n",
    "C_O_time_fos=dict()\n",
    "D_O_time_fos=dict()\n",
    "for fos in fos_list:\n",
    "    num_A_fos[fos]=dict()\n",
    "    num_B_fos[fos]=dict()\n",
    "    num_C_fos[fos]=dict()\n",
    "    num_D_fos[fos]=dict()\n",
    "    B_A_fos[fos]=dict()\n",
    "    B_D_fos[fos]=dict()\n",
    "    B_C_fos[fos]=dict()\n",
    "    D_C_fos[fos]=dict()\n",
    "    A_O_fos[fos]=dict()\n",
    "    B_O_fos[fos]=dict()\n",
    "    C_O_fos[fos]=dict()\n",
    "    D_O_fos[fos]=dict()\n",
    "    B_A_time_fos[fos]=dict()\n",
    "    B_C_time_fos[fos]=dict()\n",
    "    B_D_C_time_fos[fos]=dict()\n",
    "    D_C_time_fos[fos]=dict()\n",
    "    A_O_time_fos[fos]=dict()\n",
    "    B_O_time_fos[fos]=dict()\n",
    "    B_D_O_time_fos[fos]=dict()\n",
    "    C_O_time_fos[fos]=dict()\n",
    "    D_O_time_fos[fos]=dict()\n",
    "    for year in range(1800,2022):\n",
    "        num_A_fos[fos][year]=0\n",
    "        num_B_fos[fos][year]=0\n",
    "        num_C_fos[fos][year]=0\n",
    "        num_D_fos[fos][year]=0\n",
    "        B_A_fos[fos][year]=0\n",
    "        B_D_fos[fos][year]=0\n",
    "        B_C_fos[fos][year]=0\n",
    "        D_C_fos[fos][year]=0\n",
    "        A_O_fos[fos][year]=0\n",
    "        B_O_fos[fos][year]=0\n",
    "        C_O_fos[fos][year]=0\n",
    "        D_O_fos[fos][year]=0\n",
    "        B_A_time_fos[fos][year]=list()\n",
    "        B_C_time_fos[fos][year]=list()\n",
    "        B_D_C_time_fos[fos][year]=list()\n",
    "        D_C_time_fos[fos][year]=list()\n",
    "        A_O_time_fos[fos][year]=list()\n",
    "        B_O_time_fos[fos][year]=list()\n",
    "        B_D_O_time_fos[fos][year]=list()\n",
    "        C_O_time_fos[fos][year]=list()\n",
    "        D_O_time_fos[fos][year]=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for author,career in tqdm(author_career.items()):\n",
    "    paper_num=int(career[0])\n",
    "    start=int(career[1])\n",
    "    first=int(career[2])\n",
    "    last=int(career[3])\n",
    "    AI=int(career[4])\n",
    "    drop=int(career[5])        \n",
    "    author_fos=author_selected_dict_fos[author]\n",
    "\n",
    "    if last>first and last>start and drop>start and drop<=2015:\n",
    "        count+=1\n",
    "        \n",
    "        for year in range(start,drop+1):\n",
    "            if start==AI:\n",
    "                if year==last and year>AI:\n",
    "                    D_C_time[year].append(year-start)\n",
    "\n",
    "            else: \n",
    "                if year==last and year<AI:\n",
    "                    B_A_time[year].append(year-start)\n",
    "                elif year==last and year==AI:\n",
    "                    B_C_time[year].append(year-start)\n",
    "                elif year==last and year>AI:\n",
    "                    B_D_C_time[year].append(year-start)\n",
    "\n",
    "        if start==AI:\n",
    "            if drop>=last and drop>=AI:\n",
    "                C_O_time[drop].append(drop-start)\n",
    "            elif drop<last and drop>=AI:\n",
    "                D_O_time[drop].append(drop-start)\n",
    "        else:    \n",
    "            if drop>=last and drop<AI:\n",
    "                A_O_time[drop].append(drop-start)\n",
    "            elif drop<last and drop<AI:\n",
    "                B_O_time[drop].append(drop-start)\n",
    "            elif drop>=last and drop>=AI:\n",
    "                C_O_time[drop].append(drop-start)\n",
    "            elif drop<last and drop>=AI:\n",
    "                B_D_O_time[drop].append(drop-start)\n",
    "                    \n",
    "        for fos in author_fos:\n",
    "            for year in range(start,drop+1):\n",
    "                if year>=last and year<AI:\n",
    "                    num_A_fos[fos][year]+=1\n",
    "                elif year<last and year<AI:\n",
    "                    num_B_fos[fos][year]+=1\n",
    "                elif year>=last and year>=AI:\n",
    "                    num_C_fos[fos][year]+=1\n",
    "                elif year<last and year>=AI:\n",
    "                    num_D_fos[fos][year]+=1\n",
    "\n",
    "                if start==AI:\n",
    "                    if year==last and year>AI:\n",
    "                        D_C_fos[fos][year]+=1\n",
    "                        D_C_time_fos[fos][year].append(year-start)\n",
    "\n",
    "                else: \n",
    "                    if year==last and year<AI:\n",
    "                        B_A_fos[fos][year]+=1\n",
    "                        B_A_time_fos[fos][year].append(year-start)\n",
    "                    elif year==last and year==AI:\n",
    "                        B_C_fos[fos][year]+=1\n",
    "                        B_C_time_fos[fos][year].append(year-start)\n",
    "                    elif year==last and year>AI:\n",
    "                        D_C_fos[fos][year]+=1\n",
    "                        B_D_C_time_fos[fos][year].append(year-start)\n",
    "                    elif year<last and year==AI:\n",
    "                        B_D_fos[fos][year]+=1\n",
    "\n",
    "            if start==AI:\n",
    "                if drop>=last and drop>=AI:\n",
    "                    C_O_fos[fos][drop]+=1\n",
    "                    C_O_time_fos[fos][drop].append(drop-start)\n",
    "                elif drop<last and drop>=AI:\n",
    "                    D_O_fos[fos][drop]+=1\n",
    "                    D_O_time_fos[fos][drop].append(drop-start)\n",
    "            else:    \n",
    "                if drop>=last and drop<AI:\n",
    "                    A_O_fos[fos][drop]+=1\n",
    "                    A_O_time_fos[fos][drop].append(drop-start)\n",
    "                elif drop<last and drop<AI:\n",
    "                    B_O_fos[fos][drop]+=1\n",
    "                    B_O_time_fos[fos][drop].append(drop-start)\n",
    "                elif drop>=last and drop>=AI:\n",
    "                    C_O_fos[fos][drop]+=1\n",
    "                    C_O_time_fos[fos][drop].append(drop-start)\n",
    "                elif drop<last and drop>=AI:\n",
    "                    D_O_fos[fos][drop]+=1\n",
    "                    B_D_O_time_fos[fos][drop].append(drop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b384123",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start=1990\n",
    "year_end=2015\n",
    "years=range(year_start,year_end+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval(data,confidence=0.99):\n",
    "    return stats.t.interval(confidence=confidence, df=len(data)-1, loc=np.mean(data), scale=stats.sem(data))\n",
    "\n",
    "def interval_diff(data1,data2,confidence=0.99):\n",
    "    s1=stats.sem(data1)**2\n",
    "    s2=stats.sem(data2)**2\n",
    "    \n",
    "    return stats.t.interval(confidence=confidence, df=(s1+s2)**2/(s1**2/(len(data1)-1)+s2**2/(len(data2)-1)), loc=np.mean(data1)-np.mean(data2), scale=(s1+s2)**0.5)\n",
    "\n",
    "# def interval_div(data1,data2,n_boot=10000,confidence=0.99):\n",
    "#     data_boot_mean1=np.mean(np.random.choice(data1,replace=True,size=(n_boot,len(data1))),axis=1)\n",
    "#     data_boot_mean2=np.mean(np.random.choice(data2,replace=True,size=(n_boot,len(data2))),axis=1)\n",
    "#     data_boot_mean_div=data_boot_mean1/data_boot_mean2\n",
    "    \n",
    "#     return (np.percentile(data_boot_mean_div,50-50*confidence),np.percentile(data_boot_mean_div,50+50*confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65067681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_quitting=pd.DataFrame(columns=['Field','Type','Year','Value'])\n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_prob_quitting=df_prob_quitting.append({'Field':fos.capitalize(),'Type':'NonAI','Year':year,'Value':B_O_fos[fos][year]/(B_O_fos[fos][year]+B_A_fos[fos][year])},ignore_index=True)\n",
    "        df_prob_quitting=df_prob_quitting.append({'Field':fos.capitalize(),'Type':'AI-enabled','Year':year,'Value':D_O_fos[fos][year]/(D_O_fos[fos][year]+D_C_fos[fos][year])},ignore_index=True)    \n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_prob_quitting=df_prob_quitting.append({'Field':'Total','Type':'NonAI','Year':year,'Value':B_O_fos[fos][year]/(B_O_fos[fos][year]+B_A_fos[fos][year])},ignore_index=True)\n",
    "        df_prob_quitting=df_prob_quitting.append({'Field':'Total','Type':'AI-enabled','Year':year,'Value':D_O_fos[fos][year]/(D_O_fos[fos][year]+D_C_fos[fos][year])},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec582f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10.5,6))\n",
    "\n",
    "value_list=list()\n",
    "interval_list=list()\n",
    "for i,fos in enumerate(sorted(fos_list)+['total']):\n",
    "    df_fos=df_prob_quitting[df_prob_quitting['Field']==fos.capitalize()]\n",
    "    AI_data=np.array(df_fos[df_fos['Type']=='AI-enabled']['Value'].to_list())\n",
    "    NonAI_data=np.array(df_fos[df_fos['Type']=='NonAI']['Value'].to_list())\n",
    "    value_list.append(np.mean(AI_data/NonAI_data))\n",
    "    interval_fos=interval(AI_data/NonAI_data)\n",
    "    interval_list.append(interval_fos)\n",
    "    p=stats.ttest_ind(AI_data,NonAI_data).pvalue\n",
    "#     plt.text(x=i-0.03,y=interval_fos[0]-0.05,s=('p=%.3f'%p if p>=0.001 else 'p<0.001'),va='center',ha='center',fontsize=15)\n",
    "    print('%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f'%((np.mean(NonAI_data),)+interval(NonAI_data)+(np.mean(AI_data),)+interval(AI_data)+(np.mean(AI_data)/np.mean(NonAI_data),)+interval_fos+(p,)))\n",
    "plt.errorbar(np.arange(len(fos_name_list))-0.2,value_list,yerr=np.abs(np.vstack(interval_list).T-value_list),fmt='o',marker='o',markersize=8,markerfacecolor='white',markeredgewidth=2,markeredgecolor='darkorange',ecolor='darkorange',elinewidth=2,capsize=10,capthick=2,label='Quit the academia',zorder=1)\n",
    "\n",
    "print()\n",
    "value_list=list()\n",
    "interval_list=list()\n",
    "for i,fos in enumerate(sorted(fos_list)+['total']):\n",
    "    df_fos=df_prob_quitting[df_prob_quitting['Field']==fos.capitalize()]\n",
    "    AI_data=1-np.array(df_fos[df_fos['Type']=='AI-enabled']['Value'].to_list())\n",
    "    NonAI_data=1-np.array(df_fos[df_fos['Type']=='NonAI']['Value'].to_list())\n",
    "    value_list.append(np.mean(AI_data/NonAI_data))\n",
    "    interval_fos=interval(AI_data/NonAI_data)\n",
    "    interval_list.append(interval_fos)\n",
    "    p=stats.ttest_ind(AI_data,NonAI_data).pvalue\n",
    "    plt.text(x=i+0.03,y=interval_fos[1]+0.03,s=('p=%.3f'%p if p>=0.001 else 'p<0.001'),va='center',ha='center',fontsize=15)\n",
    "    print('%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f'%((np.mean(NonAI_data),)+interval(NonAI_data)+(np.mean(AI_data),)+interval(AI_data)+(np.mean(AI_data)/np.mean(NonAI_data),)+interval_fos+(p,)))\n",
    "plt.errorbar(np.arange(len(fos_name_list))+0.2,value_list,yerr=np.abs(np.vstack(interval_list).T-value_list),fmt='o',marker='o',markersize=8,markerfacecolor='white',markeredgewidth=2,markeredgecolor='forestgreen',ecolor='forestgreen',elinewidth=2,capsize=10,capthick=2,label='Become team leader',zorder=1)\n",
    "\n",
    "plt.xticks(range(len(fos_name_list)),sorted(fos_name_list),fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Relative probability: AI/without AI',fontsize=20)\n",
    "plt.xlabel('Field of study',fontsize=20)\n",
    "plt.legend(fontsize=20,loc='upper center',ncol=2,handletextpad=0.1)\n",
    "axis=plt.axis()\n",
    "xmin=axis[0]\n",
    "xmax=axis[1]\n",
    "ymin=axis[-2]\n",
    "ymax=axis[-1]\n",
    "plt.vlines(x=np.array(range(1,len(fos_list)+1))-0.5,ymin=0.6,ymax=1.8,color='lightgrey',linestyle='--',zorder=0)\n",
    "plt.hlines(y=1,xmin=xmin,xmax=xmax,color='grey',linestyle='--',zorder=0)\n",
    "plt.xlim(-0.5,len(fos_list)+0.5)\n",
    "plt.ylim(0.6,1.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a5896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_time=pd.DataFrame(columns=['Field','Type','Year','Value'])\n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_time=df_time.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'without AI','Year':year,'Value':B_A_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time=df_time.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'AI-enabled','Year':year,'Value':D_C_time_fos[fos][year]}),ignore_index=True)\n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_time=df_time.append(pd.DataFrame({'Field':'Total','Type':'without AI','Year':year,'Value':B_A_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time=df_time.append(pd.DataFrame({'Field':'Total','Type':'AI-enabled','Year':year,'Value':D_C_time_fos[fos][year]}),ignore_index=True)  \n",
    "\n",
    "plt.figure(figsize=(10.5,6))\n",
    "g=sns.barplot(data=df_time, x='Field', y='Value', hue='Type',errorbar=interval, palette=['royalblue','red'],alpha=0.6,capsize=0.2,errwidth=1.5)\n",
    "g.legend_.remove()\n",
    "plt.xticks(range(len(fos_name_list)),sorted(fos_name_list),fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Transition time to team leader (years)',fontsize=20)\n",
    "plt.xlabel('Field of study',fontsize=20)\n",
    "axis=plt.axis()\n",
    "ymin=axis[-2]\n",
    "ymax=axis[-1]\n",
    "plt.vlines(x=np.array(range(1,len(fos_list)+1))-0.5,ymin=ymin,ymax=1.1*ymax,color='lightgrey',linestyle='--')\n",
    "for i,fos in enumerate(sorted(fos_list)+['total']):\n",
    "    df_fos=df_time[df_time['Field']==fos.capitalize()]\n",
    "    AI_data=df_fos[df_fos['Type']=='AI-enabled']['Value'].to_list()\n",
    "    NonAI_data=df_fos[df_fos['Type']=='without AI']['Value'].to_list()\n",
    "    p=stats.ttest_ind(AI_data,NonAI_data).pvalue\n",
    "    plt.text(x=i,y=ymax,s=('p=%.3f'%p if p>=0.001 else 'p<0.001'),va='center',ha='center',fontsize=15)\n",
    "    print('%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f'%((np.mean(NonAI_data),)+interval(NonAI_data)+(np.mean(AI_data),)+interval(AI_data)+(np.mean(NonAI_data)-np.mean(AI_data),)+interval_diff(NonAI_data,AI_data)+(p,)))\n",
    "plt.xlim(-0.5,len(fos_list)+0.5)\n",
    "plt.ylim(ymin,ymax*1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac685f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_total=pd.DataFrame(columns=['Field','Type','Year','Value'])\n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'without AI','Year':year,'Value':B_O_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'AI-enabled','Year':year,'Value':D_O_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'without AI','Year':year,'Value':B_A_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':fos.capitalize(),'Type':'AI-enabled','Year':year,'Value':D_C_time_fos[fos][year]}),ignore_index=True)\n",
    "for year in years:    \n",
    "    for fos in sorted(fos_list):\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':'Total','Type':'without AI','Year':year,'Value':B_O_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':'Total','Type':'AI-enabled','Year':year,'Value':D_O_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':'Total','Type':'without AI','Year':year,'Value':B_A_time_fos[fos][year]}),ignore_index=True)\n",
    "        df_time_total=df_time_total.append(pd.DataFrame({'Field':'Total','Type':'AI-enabled','Year':year,'Value':D_C_time_fos[fos][year]}),ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(10.5,6))\n",
    "g=sns.barplot(data=df_time_total, x='Field', y='Value', hue='Type',errorbar=interval, palette=['royalblue','red'],alpha=0.6,capsize=0.2,errwidth=1.5)\n",
    "g.legend_.remove()\n",
    "plt.xticks(range(len(fos_name_list)),sorted(fos_name_list),fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('Duration of junior status (years)',fontsize=20)\n",
    "plt.xlabel('Field of study',fontsize=20)\n",
    "axis=plt.axis()\n",
    "ymin=axis[-2]\n",
    "ymax=axis[-1]\n",
    "plt.vlines(x=np.array(range(1,len(fos_list)+1))-0.5,ymin=ymin,ymax=1.1*ymax,color='lightgrey',linestyle='--')\n",
    "for i,fos in enumerate(sorted(fos_list)+['total']):\n",
    "    df_fos=df_time_total[df_time_total['Field']==fos.capitalize()]\n",
    "    AI_data=df_fos[df_fos['Type']=='AI-enabled']['Value'].to_list()\n",
    "    NonAI_data=df_fos[df_fos['Type']=='without AI']['Value'].to_list()\n",
    "    p=stats.ttest_ind(AI_data,NonAI_data).pvalue\n",
    "    plt.text(x=i,y=ymax,s=('p=%.3f'%p if p>=0.001 else 'p<0.001'),va='center',ha='center',fontsize=15)\n",
    "    print('%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f\\t%.3f-%.3f\\t%.3f'%((np.mean(NonAI_data),)+interval(NonAI_data)+(np.mean(AI_data),)+interval(AI_data)+(np.mean(NonAI_data)-np.mean(AI_data),)+interval_diff(NonAI_data,AI_data)+(p,)))\n",
    "plt.xlim(-0.5,len(fos_list)+0.5)\n",
    "plt.ylim(ymin,ymax*1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, lam):\n",
    "    return lam*np.exp(-lam * x)\n",
    "\n",
    "def R_square(y,y_hat):\n",
    "    y_bar=np.mean(y)\n",
    "    return np.sum(np.square(y_hat-y_bar))/np.sum(np.square(y-y_bar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AI_tolead=list()\n",
    "data_NonAI_tolead=list()\n",
    "data_AI_dropout=list()\n",
    "data_NonAI_dropout=list()\n",
    "for year in years:\n",
    "    data_NonAI_dropout.extend(B_O_time[year])\n",
    "    data_NonAI_tolead.extend(B_A_time[year])\n",
    "    data_AI_dropout.extend(D_O_time[year]+B_D_O_time[year])\n",
    "    data_AI_tolead.extend(D_C_time[year])\n",
    "    \n",
    "data_AI_tolead=np.array(data_AI_tolead)\n",
    "data_NonAI_tolead=np.array(data_NonAI_tolead)\n",
    "data_AI_dropout=np.array(data_AI_dropout)\n",
    "data_NonAI_dropout=np.array(data_NonAI_dropout)\n",
    "\n",
    "freq_AI_tolead=np.bincount(data_AI_tolead)[1:]\n",
    "pdf_AI_tolead=freq_AI_tolead/np.sum(freq_AI_tolead)\n",
    "x_AI_tolead=np.array(range(1,np.max(data_AI_tolead)+1))\n",
    "lam_AI_tolead,lam_AI_tolead_cov= curve_fit(func, x_AI_tolead,pdf_AI_tolead)\n",
    "lam_AI_tolead_std=np.sqrt(np.diagonal(lam_AI_tolead_cov))\n",
    "x_AI_tolead_curve=np.array(range(0,np.max(data_AI_tolead)+2))\n",
    "fit_AI_tolead=func(x_AI_tolead_curve,lam_AI_tolead)\n",
    "fit_AI_tolead_upper=func(x_AI_tolead_curve,lam_AI_tolead+2.5758293035489004*lam_AI_tolead_std)\n",
    "fit_AI_tolead_lower=func(x_AI_tolead_curve,lam_AI_tolead-2.5758293035489004*lam_AI_tolead_std)\n",
    "print('%.3f %.3f-%.3f'%(1/lam_AI_tolead[0]+1,1/(lam_AI_tolead+2.5758293035489004*lam_AI_tolead_std)[0]+1,1/(lam_AI_tolead-2.5758293035489004*lam_AI_tolead_std)[0]+1))\n",
    "\n",
    "freq_NonAI_tolead=np.bincount(data_NonAI_tolead)[1:]\n",
    "pdf_NonAI_tolead=freq_NonAI_tolead/np.sum(freq_NonAI_tolead)\n",
    "x_NonAI_tolead=np.array(range(1,np.max(data_NonAI_tolead)+1))\n",
    "lam_NonAI_tolead,lam_NonAI_tolead_cov= curve_fit(func, x_NonAI_tolead,pdf_NonAI_tolead)\n",
    "lam_NonAI_tolead_std=np.sqrt(np.diagonal(lam_NonAI_tolead_cov))\n",
    "x_NonAI_tolead_curve=np.array(range(0,np.max(data_NonAI_tolead)+2))\n",
    "fit_NonAI_tolead=func(x_NonAI_tolead_curve,lam_NonAI_tolead)\n",
    "fit_NonAI_tolead_upper=func(x_NonAI_tolead_curve,lam_NonAI_tolead+2.5758293035489004*lam_NonAI_tolead_std)\n",
    "fit_NonAI_tolead_lower=func(x_NonAI_tolead_curve,lam_NonAI_tolead-2.5758293035489004*lam_NonAI_tolead_std)\n",
    "print('%.3f %.3f-%.3f'%(1/lam_NonAI_tolead[0]+1,1/(lam_NonAI_tolead+2.5758293035489004*lam_NonAI_tolead_std)[0]+1,1/(lam_NonAI_tolead-2.5758293035489004*lam_NonAI_tolead_std)[0]+1))\n",
    "\n",
    "freq_AI_dropout=np.bincount(data_AI_dropout)[1:]\n",
    "pdf_AI_dropout=freq_AI_dropout/np.sum(freq_AI_dropout)\n",
    "x_AI_dropout=np.array(range(1,np.max(data_AI_dropout)+1))\n",
    "lam_AI_dropout,lam_AI_dropout_cov= curve_fit(func, x_AI_dropout,pdf_AI_dropout)\n",
    "lam_AI_dropout_std=np.sqrt(np.diagonal(lam_AI_dropout_cov))\n",
    "x_AI_dropout_curve=np.array(range(0,np.max(data_AI_dropout)+2))\n",
    "fit_AI_dropout=func(x_AI_dropout_curve,lam_AI_dropout)\n",
    "fit_AI_dropout_upper=func(x_AI_dropout_curve,lam_AI_dropout+2.5758293035489004*lam_AI_dropout_std)\n",
    "fit_AI_dropout_lower=func(x_AI_dropout_curve,lam_AI_dropout-2.5758293035489004*lam_AI_dropout_std)\n",
    "print('%.3f %.3f-%.3f'%(1/lam_AI_dropout[0]+1,1/(lam_AI_dropout+2.5758293035489004*lam_AI_dropout_std)[0]+1,1/(lam_AI_dropout-2.5758293035489004*lam_AI_dropout_std)[0]+1))\n",
    "\n",
    "freq_NonAI_dropout=np.bincount(data_NonAI_dropout)[1:]\n",
    "pdf_NonAI_dropout=freq_NonAI_dropout/np.sum(freq_NonAI_dropout)\n",
    "x_NonAI_dropout=np.array(range(1,np.max(data_NonAI_dropout)+1))\n",
    "lam_NonAI_dropout,lam_NonAI_dropout_cov= curve_fit(func, x_NonAI_dropout,pdf_NonAI_dropout)\n",
    "lam_NonAI_dropout_std=np.sqrt(np.diagonal(lam_NonAI_dropout_cov))\n",
    "x_NonAI_dropout_curve=np.array(range(0,np.max(data_NonAI_dropout)+2))\n",
    "fit_NonAI_dropout=func(x_NonAI_dropout_curve,lam_NonAI_dropout)\n",
    "fit_NonAI_dropout_upper=func(x_NonAI_dropout_curve,lam_NonAI_dropout+2.5758293035489004*lam_NonAI_dropout_std)\n",
    "fit_NonAI_dropout_lower=func(x_NonAI_dropout_curve,lam_NonAI_dropout-2.5758293035489004*lam_NonAI_dropout_std)\n",
    "print('%.3f %.3f-%.3f'%(1/lam_NonAI_dropout[0]+1,1/(lam_NonAI_dropout+2.5758293035489004*lam_NonAI_dropout_std)[0]+1,1/(lam_NonAI_dropout-2.5758293035489004*lam_NonAI_dropout_std)[0]+1))\n",
    "\n",
    "plt.figure(figsize=(10.5,8))\n",
    "plt.scatter(x_NonAI_dropout,pdf_NonAI_dropout,color='royalblue',marker='^',label='without AI',s=60)\n",
    "plt.scatter(x_AI_dropout,pdf_AI_dropout,color='red',marker='o',label='AI-enabled',s=60)\n",
    "plt.plot(x_NonAI_dropout_curve,fit_NonAI_dropout,color='royalblue',linestyle='--',linewidth=2)\n",
    "plt.fill_between(x_NonAI_dropout_curve,fit_NonAI_dropout_upper,fit_NonAI_dropout_lower,color='royalblue',alpha=0.2)\n",
    "plt.plot(x_AI_dropout_curve,fit_AI_dropout,color='red',linestyle='--',linewidth=2)\n",
    "plt.fill_between(x_AI_dropout_curve,fit_AI_dropout_upper,fit_AI_dropout_lower,color='red',alpha=0.2)\n",
    "plt.text(x=11,y=0.2,s=r'$p\\sim \\lambda e^{{-\\lambda t}}$',color='black',size=25,va='center',ha='center')\n",
    "plt.annotate(r'$\\lambda=%.3f,t_{{avg}}=%.2f$'%(lam_NonAI_dropout[0],1/lam_NonAI_dropout[0]+1), xy = (3, fit_NonAI_dropout[3]), xytext = (5, 0.16), color='blue',size=20,va='center',ha='left',\n",
    "             arrowprops = {'headwidth': 10, 'headlength': 10, 'width': 2, 'facecolor': 'blue','edgecolor':'blue', 'shrink': 0})\n",
    "plt.annotate(r'$\\lambda=%.3f,t_{{avg}}=%.2f$'%(lam_AI_dropout[0],1/lam_AI_dropout[0]+1), xy = (2, fit_AI_dropout[2]), xytext = (5, 0.18), color='red',size=20,va='center',ha='left',\n",
    "             arrowprops = {'headwidth': 10, 'headlength': 10, 'width': 2, 'facecolor': 'red','edgecolor':'red', 'shrink': 0})\n",
    "# plt.text(x=12.5,y=0.125,s='{',color='black',size=40,va='center',ha='left',fontdict={'weight':'light'})\n",
    "# plt.text(x=13.8,y=0.135,s=r'without AI: $\\lambda=%.3f,t_{{avg}}=%.3f$'%(lam_NonAI_dropout[0],1/lam_NonAI_dropout[0]+1),color='blue',size=20,va='center',ha='left')\n",
    "# plt.text(x=13.8,y=0.115,s=r'AI-enabled: $\\lambda=%.3f,t_{{avg}}=%.3f$'%(lam_AI_dropout[0],1/lam_AI_dropout[0]+1),color='red',size=20,va='center',ha='left')\n",
    "print('R^2=%.3f'%R_square(pdf_AI_dropout,fit_AI_dropout[1:-1]))\n",
    "print('R^2=%.3f'%R_square(pdf_NonAI_dropout,fit_NonAI_dropout[1:-1]))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Transition time to quitting the academia ($t$ / years)',fontsize=20)\n",
    "plt.ylabel('Probablity density ($p$)',fontsize=20)\n",
    "# plt.legend(fontsize=20)\n",
    "plt.grid(True, linestyle=\"--\", alpha=1)\n",
    "plt.xlim(0,36)\n",
    "plt.ylim(-0.003,0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10.5,8))\n",
    "plt.scatter(x_AI_tolead,pdf_AI_tolead,color='red',marker='o',label='AI-enabled',s=60)\n",
    "plt.scatter(x_NonAI_tolead,pdf_NonAI_tolead,color='royalblue',marker='^',label='without AI',s=60)\n",
    "plt.plot(x_AI_tolead_curve,fit_AI_tolead,color='red',linestyle='--',linewidth=2)\n",
    "plt.fill_between(x_AI_tolead_curve,fit_AI_tolead_upper,fit_AI_tolead_lower,color='red',alpha=0.2)\n",
    "plt.plot(x_NonAI_tolead_curve,fit_NonAI_tolead,color='royalblue',linestyle='--',linewidth=2)\n",
    "plt.fill_between(x_NonAI_tolead_curve,fit_NonAI_tolead_upper,fit_NonAI_tolead_lower,color='royalblue',alpha=0.2)\n",
    "plt.text(x=11,y=0.2,s=r'$p\\sim \\lambda e^{{-\\lambda t}}$',color='black',size=25,va='center',ha='center')\n",
    "plt.annotate(r'$\\lambda=%.3f,t_{{avg}}=%.2f$'%(lam_NonAI_tolead[0],1/lam_NonAI_tolead[0]+1), xy = (3, fit_NonAI_tolead[3]), xytext = (5, 0.16), color='blue',size=20,va='center',ha='left',\n",
    "             arrowprops = {'headwidth': 10, 'headlength': 10, 'width': 2, 'facecolor': 'blue','edgecolor':'blue', 'shrink': 0})\n",
    "plt.annotate(r'$\\lambda=%.3f,t_{{avg}}=%.2f$'%(lam_AI_tolead[0],1/lam_AI_tolead[0]+1), xy = (2, fit_AI_tolead[2]), xytext = (5, 0.18), color='red',size=20,va='center',ha='left',\n",
    "             arrowprops = {'headwidth': 10, 'headlength': 10, 'width': 2, 'facecolor': 'red','edgecolor':'red', 'shrink': 0})\n",
    "# plt.text(x=12.5,y=0.125,s='{',color='black',size=40,va='center',ha='left',fontdict={'weight':'light'})\n",
    "# plt.text(x=13.8,y=0.135,s=r'without AI: $\\lambda=%.3f,t_{{avg}}=%.3f$'%(lam_NonAI_tolead[0],1/lam_NonAI_tolead[0]+1),color='blue',size=20,va='center',ha='left')\n",
    "# plt.text(x=13.8,y=0.115,s=r'AI-enabled: $\\lambda=%.3f,t_{{avg}}=%.3f$'%(lam_AI_tolead[0],1/lam_AI_tolead[0]+1),color='red',size=20,va='center',ha='left')\n",
    "print('R^2=%.3f'%R_square(pdf_AI_tolead,fit_AI_tolead[1:-1]))\n",
    "print('R^2=%.3f'%R_square(pdf_NonAI_tolead,fit_NonAI_tolead[1:-1]))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Transition time to team leader ($t$ / years)',fontsize=20)\n",
    "plt.ylabel('Probablity density ($p$)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(True, linestyle=\"--\", alpha=1)\n",
    "plt.xlim(0,36)\n",
    "plt.ylim(-0.003,0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
